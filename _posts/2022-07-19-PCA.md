Principle Component Analysis(PCA)
================
Lan Lin
2022-07-19

Principal component analysis(PCA) in R programming is an analysis of the
linear components of all existing attributes. Principal components are
linear combinations (orthogonal transformation) of the original
predictor in the dataset. It is a useful technique for EDA(Exploratory
data analysis) and allows you to better visualize the variations present
in a dataset with many variables.

For example,having expression data for thousands of genes can be
overwhelming to explore! Here we will show how to use PCA (principal
component analysis). This is a good example of a multi-dimensional
dataset: we have many variables (genes) that we want to use to
understand patterns of similarity between our samples (yeast cells).

To compute a PCA in R we can use the prcomp() function. This function
takes a matrix of data, where the columns are the variables that we want
to use to transform our samples, which should be the rows of the matrix.

``` r
# Create a matrix from our table of counts
pca_matrix <- trans_cts %>% 
  # make the "gene" column become the rownames of the table
  column_to_rownames("gene") %>% 
  # coerce to a matrix
  as.matrix() %>% 
  # transpose the matrix so that rows = samples and columns = variables
  t()

# Perform the PCA
sample_pca <- prcomp(pca_matrix)
```

The first important question to ask after we do a PCA is how many PCs we
have and how much variance they explain.

We need to extract the variance explained by each PC from our sample_pca
object. prcomp() returns an object of its own class. To access
individual elements from this object, we use the $ notation, similarly
to how you can access individual columns from a data.frame.

``` r
#biplot(sample_pca, xlabs = rep(".", nrow(trans_cts)), cex = 1.2)
pc_eigenvalues <- sample_pca$sdev^2
# create a "tibble" manually with 
# a variable indicating the PC number
# and a variable with the variances
pc_eigenvalues <- tibble(PC = factor(1:length(pc_eigenvalues)), 
                         variance = pc_eigenvalues) %>% 
  # add a new column with the percent variance
  mutate(pct = variance/sum(variance)*100) %>% 
  # add another column with the cumulative variance explained
  mutate(pct_cum = cumsum(pct))

# print the result
pc_eigenvalues
```

    ## # A tibble: 36 × 4
    ##    PC    variance   pct pct_cum
    ##    <fct>    <dbl> <dbl>   <dbl>
    ##  1 1        351.  38.8     38.8
    ##  2 2        147.  16.3     55.2
    ##  3 3         76.7  8.50    63.7
    ##  4 4         51.2  5.67    69.3
    ##  5 5         48.8  5.41    74.7
    ##  6 6         29.5  3.26    78.0
    ##  7 7         27.0  2.99    81.0
    ##  8 8         16.8  1.86    82.8
    ##  9 9         14.3  1.59    84.4
    ## 10 10        13.5  1.49    85.9
    ## # … with 26 more rows

This table can now be used to produce a Scree Plot, which shows the
fraction of total variance explained by each principal component. We
will show both the variance explained by individual PCs as well as the
cumulative variance, using a type of visualisation known as a pareto
chart:

``` r
pc_eigenvalues %>% 
  ggplot(aes(x = PC)) +
  geom_col(aes(y = pct)) +
  geom_line(aes(y = pct_cum, group = 1)) + 
  geom_point(aes(y = pct_cum)) +
  labs(x = "Principal component", y = "Fraction variance explained")
```

![](../images/unnamed-chunk-11-1.png)<!-- -->

Next, we turn to visualising our samples on the new PC coordinate

``` r
# The PC scores are stored in the "x" value of the prcomp object
pc_scores <- sample_pca$x
pc_scores <- pc_scores %>% 
  # convert to a tibble retaining the sample names as a new column
  as_tibble(rownames = "sample")

# print the result
pc_scores
```

    ## # A tibble: 36 × 37
    ##    sample      PC1    PC2     PC3     PC4    PC5     PC6    PC7    PC8    PC9
    ##    <chr>     <dbl>  <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>  <dbl>  <dbl>
    ##  1 wt_0_r1  -21.5    5.53   0.130  -8.28  10.2    -4.45   2.93  -0.121  0.299
    ##  2 wt_0_r2  -20.9    2.80 -13.3    -0.106  7.52    0.392 -0.137 -5.90   0.900
    ##  3 wt_0_r3  -20.8    1.83 -13.5     0.402  8.98    0.263  0.170 -3.55   1.13 
    ##  4 wt_15_r1  12.2   27.9   11.1    -2.04   5.00   20.0   14.2   -3.50  -7.37 
    ##  5 wt_15_r2  11.0   20.2    5.92   -1.18  -3.16    0.975 -6.95  -2.88   5.86 
    ##  6 wt_15_r3  14.5   28.7   -4.50   26.1   -2.23  -16.8   10.5    0.393 -1.86 
    ##  7 wt_30_r1  33.1   -6.93   2.18  -10.4    3.76   -4.28   8.81   4.05   5.50 
    ##  8 wt_30_r2  35.7   -6.54 -14.8     0.719 -0.640   4.31   0.349 -3.51   2.83 
    ##  9 wt_30_r3  33.2  -13.0  -16.9     1.83   2.43    3.47   1.76  -2.14   5.72 
    ## 10 wt_60_r1  -1.87 -11.9   10.3     9.11   2.64    4.40   1.37  -2.82   5.68 
    ## # … with 26 more rows, and 27 more variables: PC10 <dbl>, PC11 <dbl>,
    ## #   PC12 <dbl>, PC13 <dbl>, PC14 <dbl>, PC15 <dbl>, PC16 <dbl>, PC17 <dbl>,
    ## #   PC18 <dbl>, PC19 <dbl>, PC20 <dbl>, PC21 <dbl>, PC22 <dbl>, PC23 <dbl>,
    ## #   PC24 <dbl>, PC25 <dbl>, PC26 <dbl>, PC27 <dbl>, PC28 <dbl>, PC29 <dbl>,
    ## #   PC30 <dbl>, PC31 <dbl>, PC32 <dbl>, PC33 <dbl>, PC34 <dbl>, PC35 <dbl>,
    ## #   PC36 <dbl>

``` r
pc_scores %>% 
  # create the plot
  ggplot(aes(x = PC1, y = PC2)) +
 geom_point()
```

![](../images/unnamed-chunk-12-1.png)<!-- -->

This is a very simple plot, but already we can see there is some
structure in our data, suggesting clusters of samples that are more
similar to each other.
